{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_to_predicate import WordPredicate\n",
    "import json\n",
    "import sentence_grounding_test_parameters as param\n",
    "import numpy as np\n",
    "from recognized_object import RecognizedObject\n",
    "\n",
    "from plots import *\n",
    "from data_processing import *\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "from reservoirpy import ESNOnline, mat_gen, ESN\n",
    "from reservoirpy.mat_gen import generate_internal_weights, generate_input_weights\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Masking, GRU\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_sentences_ESN(sentences, model, nb_concepts, threshold_factor):\n",
    "    \n",
    "    test = []\n",
    "    for s in sentences:\n",
    "        #print(s)\n",
    "        temp = []\n",
    "        for w in s.split():\n",
    "            temp.append(nlp(w))\n",
    "        temp = np.array(temp)\n",
    "        #print(temp.shape)\n",
    "        temp = np.reshape(temp,(temp.shape[0], temp.shape[2], temp.shape[3]))\n",
    "        temp = np.mean(temp, axis=1)\n",
    "        #print(np.mean(temp, axis=1).shape)\n",
    "        #print(temp.shape)\n",
    "        test.append(temp)\n",
    "    \"\"\"\n",
    "    test = [one_hot_encoding_sentence(s) for s in sentences]\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    model.reset_reservoir()\n",
    "    for i in range(len(sentences)):\n",
    "        outputs, int_states = model.run([test[i],])\n",
    "        res.append(outputs[0])\n",
    "        model.reset_reservoir()\n",
    "    return res, [output_to_vision(res[j][-1],nb_concepts, threshold_factor, concepts_delimitations, output_id_to_concept_dict) for j in range(len(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_sentences_ESN(sentences, model, nb_concepts, threshold_factor):\n",
    "    test = []\n",
    "    test = []\n",
    "    for s in sentences:\n",
    "        #print(s)\n",
    "        temp = []\n",
    "        for w in s.split():\n",
    "            temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "        #temp = np.array(nlp(s))\n",
    "        #print(temp.shape)\n",
    "        temp = np.array(temp)\n",
    "        temp = np.reshape(temp,(temp.shape[0]*temp.shape[1], temp.shape[2]))\n",
    "        #temp = np.mean(temp, axis=1)\n",
    "        #print(np.mean(temp, axis=1).shape)\n",
    "        #print(temp.shape)\n",
    "        test.append(temp)\n",
    "    res = []\n",
    "    model.reset_reservoir()\n",
    "    for i in range(len(sentences)):\n",
    "        outputs, int_states = model.run([test[i],])\n",
    "        res.append(outputs[0])\n",
    "        model.reset_reservoir()\n",
    "    return res, [output_to_vision(res[j][-1],nb_concepts, threshold_factor, concepts_delimitations, output_id_to_concept_dict) for j in range(len(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_sentences(sentences, model):\n",
    "    global max_seq_len\n",
    "    test = []\n",
    "    \n",
    "    for s in sentences:\n",
    "        #print(s)\n",
    "        temp = []\n",
    "        for w in s.split():\n",
    "            temp.append(nlp(w))\n",
    "        temp = np.array(temp)\n",
    "        #print(temp.shape)\n",
    "        temp = np.reshape(temp,(temp.shape[0], temp.shape[2], temp.shape[3]))\n",
    "        temp = np.mean(temp, axis=1)\n",
    "        #print(np.mean(temp, axis=1).shape)\n",
    "        #print(temp.shape)\n",
    "        test.append(temp)\n",
    "    test = []\n",
    "    \"\"\"\n",
    "    for s in sentences:\n",
    "        #print(s)\n",
    "        temp = []\n",
    "        #for w in s.split():\n",
    "        #    temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "        temp = np.array(nlp(s))\n",
    "        #print(temp.shape)\n",
    "        temp = np.reshape(temp,(temp.shape[0]*temp.shape[1], temp.shape[2]))\n",
    "        #temp = np.mean(temp, axis=1)\n",
    "        #print(np.mean(temp, axis=1).shape)\n",
    "        #print(temp.shape)\n",
    "        test.append(temp)\n",
    "    \"\"\"\n",
    "    #test = [one_hot_encoding_sentence(s) for s in sentences]\n",
    "    test_pad = padding(test, max_seq_len)\n",
    "    res = model.predict(test_pad)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_test_set(model, test_sentences, testX, testY, verbose, threshold_factor, online):\n",
    "\n",
    "    test_outputs = []\n",
    "    rmse = 0\n",
    "    for sent_nb in range(len(testX)):\n",
    "        if online:\n",
    "            model.reset_reservoir()\n",
    "        outputs, int_states = model.run([testX[sent_nb],])\n",
    "        test_outputs.append(outputs[0][-1])\n",
    "        rmse += np.mean( (outputs[0][-1] - testY[sent_nb])**2)\n",
    "    rmse = np.sqrt(rmse/len(testX))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"End of testing\")\n",
    "    exact = 0\n",
    "    valid = 0\n",
    "    for i in range(len(test_outputs)):\n",
    "        v = output_to_vision(test_outputs[i],nb_concepts, threshold_factor, concepts_delimitations, output_id_to_concept_dict)\n",
    "        pred = sentence_to_pred(test_sentences[i], sent_to_role)\n",
    "\n",
    "\n",
    "        if is_an_exact_representation(pred, v):\n",
    "            exact +=1\n",
    "\n",
    "        if is_a_valid_representation(pred, v):\n",
    "            valid +=1\n",
    "\n",
    "        if is_a_valid_representation(pred, v) and not(is_an_exact_representation(pred, v)):\n",
    "            pass\n",
    "\n",
    "    nb_sample = len(testX)\n",
    "    if verbose:\n",
    "        print(\"Valid representations : \", valid,\"/\", nb_sample)\n",
    "        print(\"Exact representations : \", exact, \"/\", nb_sample)\n",
    "    return 1-valid/nb_sample, 1-exact/nb_sample, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to get the evolution of the loss during training\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.exact_errors = []\n",
    "        self.valid_errors = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global validationX_pad\n",
    "        global validationY\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "        v, ex, er = test_on_test_set(self.model, validationX_pad, validationY, validation_sentences, True, 1.3)\n",
    "\n",
    "        self.val_losses.append(er)\n",
    "        self.exact_errors.append(ex)\n",
    "        self.valid_errors.append(v)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.losses, color = \"black\", label = \"loss\")\n",
    "        plt.plot(self.val_losses, color = \"red\", label = \"loss on validation set\")\n",
    "        plt.xlabel(\"epochs of training\")\n",
    "        plt.title(\"MSE during training\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        plt.title(\"Performance on validation set during training\")\n",
    "        plt.plot(self.exact_errors, color = \"blue\", label = \"exact error\")\n",
    "        plt.plot(self.valid_errors, color = \"green\", label = \"valid error\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions used to create RSSviz showing the position of the errors\n",
    "def getErrorScore(pred, obj):\n",
    "    if is_an_exact_imagined_object(pred, obj):\n",
    "        return 2\n",
    "    elif is_a_valid_imagined_object(pred, obj):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def errorCode(obj_er):\n",
    "    return (obj_er[0] + 3*obj_er[1])\n",
    "\n",
    "\n",
    "def getErrorsInfo(reservoir_state, sentences, Wout, threshold_fact = 1.3):\n",
    "    global nb_concepts, sent_to_role\n",
    "    errors = []\n",
    "    ind = 0\n",
    "    for s in sentences:\n",
    "        pred = sentence_to_pred(s, sent_to_role)\n",
    "        for i in range(len(s.split(\" \"))):\n",
    "            output = np.dot(Wout, reservoir_state[ind])\n",
    "            v = output_to_vision(output,nb_concepts, threshold_fact,\n",
    "                                 concepts_delimitations, output_id_to_concept_dict)\n",
    "            obj_errors = (getErrorScore(pred[0], v[0]), getErrorScore(pred[1], v[1]))\n",
    "            errors.append(errorCode(obj_errors))\n",
    "            ind +=1\n",
    "    return np.array(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_states(model, sentences, one_chunck = True, only_last = False, get_obj_nb = False):\n",
    "\n",
    "    #test = [one_hot_encoding_sentence(s) for s in sentences]\n",
    "    test = []\n",
    "    for s in sentences:\n",
    "        #print(s)\n",
    "        temp = []\n",
    "        for w in s.split():\n",
    "            temp.append(nlp(w))\n",
    "        temp = np.array(temp)\n",
    "        #print(temp.shape)\n",
    "        temp = np.reshape(temp,(temp.shape[0], temp.shape[2], temp.shape[3]))\n",
    "        temp = np.mean(temp, axis=1)\n",
    "        #print(np.mean(temp, axis=1).shape)\n",
    "        #print(temp.shape)\n",
    "        test.append(temp)\n",
    "    int_states_on_sent = []\n",
    "    labels = []\n",
    "\n",
    "    clause_nb = []\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        model.reset_reservoir()\n",
    "        outputs, int_states = model.run([test[i],])\n",
    "\n",
    "        if only_last:\n",
    "            int_states_on_sent.append(int_states[0][-1].reshape((int_states[0][-1].shape[0])))\n",
    "        else:\n",
    "            if one_chunck:\n",
    "                for k in range(int_states[0].shape[0]):\n",
    "                    int_states_on_sent.append(int_states[0][k].reshape((int_states[0][k].shape[0])))\n",
    "            else:\n",
    "                int_states_on_sent.append(int_states[0].reshape((int_states[0].shape[0], int_states[0].shape[1])))\n",
    "\n",
    "            if get_obj_nb:\n",
    "                words = sentences[i].split(\" \")\n",
    "                clause_id = 0\n",
    "                for w in range(len(words)):\n",
    "                    if words[w] == \"and\":\n",
    "                        clause_id +=1\n",
    "                    clause_nb.append(clause_id)\n",
    "                    if words[w] == \"and\":\n",
    "                        clause_id +=1\n",
    "                clause_nb[-1] = 3 #final states\n",
    "\n",
    "        words = sentences[i].split(\" \")\n",
    "        for j in range(1, len(words)+1):\n",
    "            labels.append(\" \".join(words[:j]))\n",
    "\n",
    "    if one_chunck:\n",
    "        int_states_on_sent = np.array(int_states_on_sent)\n",
    "\n",
    "    if get_obj_nb:\n",
    "        return int_states_on_sent, labels, np.array(clause_nb)\n",
    "    else:\n",
    "        return int_states_on_sent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hidden_states(sentence, model_for_test, state = 'cell', units_to_plot = 'all', plt_var = False, plt_sum = False):\n",
    "    activations = get_successive_outputs(sentence, model_for_test)\n",
    "\n",
    "    plot_hidden_state_activation(sentence,\n",
    "                                 activations,\n",
    "                                 state,\n",
    "                                 units_to_plot,\n",
    "                                 plot_variation = plt_var,\n",
    "                                 plot_sum = plt_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### MAIN #####################\n",
    "\n",
    "## Parameters\n",
    "\n",
    "\n",
    "add_begin_end = True #add the word \"BEGIN\" at the beggining and \"END\" at the end of all sentences ?\n",
    "verbose_training = True\n",
    "continuous_sentence_training = True # continuous or final training\n",
    "\n",
    "\n",
    "use_save = False # use saved matrices from previous run ?\n",
    "if use_save:\n",
    "    name_id = '0.8885270787313605' #example random id of the files to load\n",
    "    pth = r\"saved_ESN/\" #path to the saved arrays\n",
    "\n",
    "threshold_factor = 1.3 # the factor used to get the threshold in the creation of he discrete representation\n",
    "nb_objects = 4 #number of objects in the vocabulary used to generate the sentences (the bigger the harder)\n",
    "N = 1000 #the size of the reservoir\n",
    "\n",
    "\n",
    "#this code can be used in command line to specify the number of object and easily test different number of objects\n",
    "\n",
    "minimal_mode = False #if minimal mode is on, the ESN will only be trained and tested on test set. The only text print will be \"nb of objects, valid error on test set, exact error on test set, RMSE on test set, time to train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dataset initialisation : creation of the sentence according to the grammar\n",
    "\n",
    "param.create_dataset(nb_objects = nb_objects)\n",
    "\n",
    "#one hot encoding initialisation\n",
    "sent_to_role= param.SENTENCE_TO_ROLES\n",
    "\n",
    "\n",
    "other_words = ['and']\n",
    "if add_begin_end:\n",
    "    other_words.append(\"BEGIN\")\n",
    "    other_words.append(\"END\")\n",
    "\n",
    "init_one_hot_encoding(list(sent_to_role.keys()) + other_words)\n",
    "nb_unique_words = len(word2one_hot_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concept dictionnary initialisation (it's the link between the output position and their meaning)\n",
    "concepts = param.CATEGORIES + param.POSITIONS + param.COLORS\n",
    "\n",
    "concepts_delimitations = [(0,len(param.CATEGORIES)),\n",
    "                          (len(param.CATEGORIES),\n",
    "                          len(param.CATEGORIES) + len(param.POSITIONS)),\n",
    "                          (len(param.CATEGORIES) + len(param.POSITIONS),\n",
    "                          len(param.CATEGORIES) + len(param.POSITIONS)+ len(param.COLORS))]\n",
    "\n",
    "nb_concepts = len(concepts)\n",
    "\n",
    "output_size = 2*nb_concepts\n",
    "\n",
    "concept_to_output_id_dict = {}\n",
    "output_id_to_concept_dict = {}\n",
    "for i,c in enumerate(concepts):\n",
    "    concept_to_output_id_dict[c] = i\n",
    "    output_id_to_concept_dict[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate data\n",
    "\n",
    "sentences_one_object = list(sent_to_role.keys())\n",
    "sentences_two_objects = []\n",
    "\n",
    "for s1 in sentences_one_object:\n",
    "    for s2 in sentences_one_object:\n",
    "        sentences_two_objects.append(s1 + \" and \" + s2)\n",
    "\n",
    "#we adjust the different dictionnaries to include sentences with BEGIN and END\n",
    "\n",
    "if add_begin_end:\n",
    "    for i in range(len(sentences_one_object)):\n",
    "\n",
    "        sent_to_role[\"BEGIN \"+ sentences_one_object[i]+ \" END\"] = [0] + sent_to_role[sentences_one_object[i]] + [0]\n",
    "        sent_to_role[\"BEGIN \"+ sentences_one_object[i]] = [0] + sent_to_role[sentences_one_object[i]]\n",
    "        sent_to_role[ sentences_one_object[i] + \" END\"] = sent_to_role[sentences_one_object[i]] + [0]\n",
    "        sentences_one_object[i] = \"BEGIN \"+ sentences_one_object[i]+ \" END\"\n",
    "\n",
    "    for i in range(len(sentences_two_objects)):\n",
    "        sentences_two_objects[i] = \"BEGIN \"+ sentences_two_objects[i]+ \" END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the training, test and validation set\n",
    "\n",
    "np.random.shuffle(sentences_one_object)\n",
    "np.random.shuffle(sentences_two_objects)\n",
    "\n",
    "train_one_obj = 300\n",
    "train_two_objs = 700\n",
    "\n",
    "\n",
    "test_one_obj = 300\n",
    "test_two_objs = 700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = (sentences_one_object[:train_one_obj]\n",
    "              + sentences_two_objects[:train_two_objs])\n",
    "\n",
    "\n",
    "test_sentences = (sentences_one_object[-test_one_obj:]\n",
    "              + sentences_two_objects[-test_two_objs:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_lower_case = True\n",
    "model = BertModel.from_pretrained(\"anonymous/BERT-NLP\", output_attentions=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"anonymous/BERT-NLP\", do_lower_case=do_lower_case)\n",
    "\n",
    "nlp = pipeline('feature-extraction',model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "for s in train_sentences:\n",
    "    temp = []\n",
    "    for w in s.split():\n",
    "        temp.append(nlp(w))\n",
    "        #print(np.array(nlp(w)).shape)\n",
    "        #temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "    temp = np.array(temp)\n",
    "    temp = np.reshape(temp,(temp.shape[0], temp.shape[2], temp.shape[3]))\n",
    "    temp = np.mean(temp, axis=1)\n",
    "    #print(np.mean(temp, axis=1).shape)\n",
    "    #print(temp.shape)\n",
    "    trainX.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = []\n",
    "for s in test_sentences:\n",
    "    temp = []\n",
    "    for w in s.split():\n",
    "        temp.append(nlp(w))\n",
    "        #temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "    temp = np.array(temp)\n",
    "    temp = np.reshape(temp,(temp.shape[0],temp.shape[2], temp.shape[3]))\n",
    "    temp = np.mean(temp, axis=1)\n",
    "    #print(np.mean(temp, axis=1).shape)\n",
    "    #print(temp.shape)\n",
    "    testX.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "for s in train_sentences:\n",
    "    temp = []\n",
    "    #for w in s.split():\n",
    "    #    temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "        #print(np.array(nlp(w)).shape)\n",
    "        #temp = np.array(temp)\n",
    "    #print(np.array(nlp(s)).shape)\n",
    "    temp = np.array(nlp(s))\n",
    "    #print(temp.shape)\n",
    "    temp = np.reshape(temp,(temp.shape[0]*temp.shape[1], temp.shape[2]))\n",
    "    #temp = np.mean(temp, axis=1)\n",
    "    #print(np.mean(temp, axis=1).shape)\n",
    "    #print(temp.shape)\n",
    "    trainX.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = []\n",
    "for s in test_sentences:\n",
    "    temp = []\n",
    "    #for w in s.split():\n",
    "    #    temp.append(np.mean(np.array(nlp(w)),axis=1))\n",
    "    temp = np.array(nlp(s))\n",
    "    temp = np.reshape(temp,(temp.shape[0]*temp.shape[1],temp.shape[2]))\n",
    "    #temp = np.mean(temp, axis=1)\n",
    "    #print(np.mean(temp, axis=1).shape)\n",
    "    #print(temp.shape)\n",
    "    testX.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainX = [one_hot_encoding_sentence(s) for s in train_sentences]\n",
    "trainY = np.array([sentence_to_output_teacher_vector(s, sent_to_role, concept_to_output_id_dict, nb_concepts) for s in train_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testX = [one_hot_encoding_sentence(s) for s in test_sentences]\n",
    "testY = np.array([sentence_to_output_teacher_vector(s, sent_to_role, concept_to_output_id_dict, nb_concepts) for s in test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_unique_words = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the ESN\n",
    "#nb_unique_words = len(word2one_hot_id)\n",
    "iss = 1\n",
    "nb_features = nb_unique_words\n",
    "set_seed(None) #we test on a different and random seed each time\n",
    "\n",
    "if continuous_sentence_training: # Alexis Juven's hyper-parameters optimized through random search\n",
    "    sr = 1.3\n",
    "    sparsity = 0.81\n",
    "    leak = 0.04\n",
    "    alpha_coef = 10.**(-3.7)\n",
    "else:\n",
    "    sr = 1.1\n",
    "    sparsity = 0.85\n",
    "    leak = 0.05\n",
    "    alpha_coef = 10.**(-3.5)\n",
    "\n",
    "\n",
    "\n",
    "# build an ESN online, i.e. trained with FORCE learning after each sample\n",
    "\n",
    "W = mat_gen.fast_spectral_initialization(N, spectral_radius=sr, proba = sparsity) #reservoir matrix\n",
    "Win = mat_gen.generate_input_weights(nbr_neuron=N, dim_input=nb_features, #input matrix\n",
    "                                    input_bias=True, input_scaling=iss)\n",
    "Wout = np.zeros((output_size, N+1)) #output matrix to be optimized\n",
    "\n",
    "\n",
    "reservoir = ESNOnline(lr = leak,\n",
    "                    W = W,\n",
    "                    Win = Win,\n",
    "                    Wout = Wout,\n",
    "                    alpha_coef = alpha_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advancement :\n",
      "0.0\n",
      "Advancement :\n",
      "0.1\n",
      "Advancement :\n",
      "0.2\n",
      "Advancement :\n",
      "0.3\n",
      "Advancement :\n",
      "0.4\n",
      "Advancement :\n",
      "0.5\n",
      "Advancement :\n",
      "0.6\n",
      "Advancement :\n",
      "0.7\n",
      "Advancement :\n",
      "0.8\n",
      "Advancement :\n",
      "0.9\n",
      "CPU Time to train :  795.6945303759994  s\n",
      "Saving the matrices ...\n",
      "ID for file saved : 0.08795020506370776\n",
      "Matrices saved !\n",
      "Testing on test set...\n",
      "End of testing\n",
      "Valid representations :  966 / 1000\n",
      "Exact representations :  834 / 1000\n",
      "Testing on train set...\n",
      "End of testing\n",
      "Valid representations :  999 / 1000\n",
      "Exact representations :  829 / 1000\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1):\n",
    "    ## create the ESN\n",
    "    #nb_unique_words = len(word2one_hot_id)\n",
    "    iss = 1\n",
    "    nb_features = nb_unique_words\n",
    "    set_seed(None) #we test on a different and random seed each time\n",
    "\n",
    "    if continuous_sentence_training: # Alexis Juven's hyper-parameters optimized through random search\n",
    "        sr = 1.3\n",
    "        sparsity = 0.81\n",
    "        leak = 0.04\n",
    "        alpha_coef = 10.**(-3.7)\n",
    "    else:\n",
    "        sr = 1.1\n",
    "        sparsity = 0.85\n",
    "        leak = 0.05\n",
    "        alpha_coef = 10.**(-3.5)\n",
    "\n",
    "\n",
    "\n",
    "    # build an ESN online, i.e. trained with FORCE learning after each sample\n",
    "\n",
    "    W = mat_gen.fast_spectral_initialization(N, spectral_radius=sr, proba = sparsity) #reservoir matrix\n",
    "    Win = mat_gen.generate_input_weights(N, dim_input=nb_features, #input matrix\n",
    "                                        input_bias=True, input_scaling=iss)\n",
    "    Wout = np.zeros((output_size, N+1)) #output matrix to be optimized\n",
    "\n",
    "\n",
    "    reservoir = ESNOnline(lr = leak,\n",
    "                        W = W,\n",
    "                        Win = Win,\n",
    "                        Wout = Wout,\n",
    "                        alpha_coef = alpha_coef)\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        if use_save:\n",
    "            Wout = np.load(pth+\"Wout\"+name_id+\".npy\", allow_pickle = True)\n",
    "            Win = np.load(pth+\"Win\"+name_id+\".npy\", allow_pickle = True)\n",
    "            W = np.load(pth+\"W\"+name_id+\".npy\", allow_pickle = True)\n",
    "            W = W.item()\n",
    "            reservoir = ESNOnline(lr = leak,\n",
    "                                W = W,\n",
    "                                Win = Win,\n",
    "                                Wout = Wout,\n",
    "                                alpha_coef = alpha_coef)\n",
    "\n",
    "        if not(use_save):\n",
    "            t1 = time.process_time()\n",
    "\n",
    "            for sent_nb in range(len(trainX)): #training sentences\n",
    "\n",
    "                if continuous_sentence_training:\n",
    "                    wash_init_steps = 0 #we train at each step\n",
    "                else:\n",
    "                    wash_init_steps = trainX[sent_nb].shape[0]-1 #we train only the last step\n",
    "\n",
    "\n",
    "                reservoir.reset_reservoir()\n",
    "                reservoir.train(inputs=np.array([trainX[sent_nb]]),\n",
    "                                teachers=np.array([[trainY[sent_nb]]*trainX[sent_nb].shape[0]]), #the teacher is always the same vector\n",
    "                                wash_nr_time_step=wash_init_steps,\n",
    "                                verbose=False)\n",
    "\n",
    "\n",
    "                if sent_nb%100 == 0 and verbose_training:\n",
    "                    print(\"Advancement :\")\n",
    "                    print( sent_nb/len(trainX))\n",
    "\n",
    "\n",
    "            t2 = time.process_time()\n",
    "            if verbose_training:\n",
    "                print(\"CPU Time to train : \", t2 - t1, \" s\")\n",
    "\n",
    "            ##saving\n",
    "            if not(minimal_mode):\n",
    "                print(\"Saving the matrices ...\")\n",
    "                rd_id = np.random.random()\n",
    "                print(\"ID for file saved : \"+ str(rd_id))\n",
    "                np.save(r\"saved_ESN/Wout\"+str(rd_id), Wout)\n",
    "                np.save(r\"saved_ESN/Win\"+str(rd_id), Win)\n",
    "                np.save(r\"saved_ESN/W\"+str(rd_id), W)\n",
    "                print(\"Matrices saved !\")\n",
    "\n",
    "            ##Testing\n",
    "            if verbose_training:\n",
    "                print(\"Testing on test set...\")\n",
    "            vtest, extest, rmsetest = test_on_test_set(reservoir, test_sentences, testX, testY, verbose_training, threshold_factor, True)\n",
    "\n",
    "            if minimal_mode:\n",
    "                print(str(nb_objects) + \",\" +str(vtest) + \",\" + str(extest) + \",\"+ str(rmsetest) + \",\" + str(t2-t1))\n",
    "\n",
    "            if not(minimal_mode):\n",
    "                print(\"Testing on train set...\") #to compare for overfitting estimation\n",
    "                vtr, extr, rmsetr = test_on_test_set(reservoir, train_sentences, trainX, trainY, True, threshold_factor, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEdCAYAAACfcGe/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABExUlEQVR4nO2deZhcVZn/P9+ETaKAKAKiGBAFZGsQRUBCI6vCxAWVEXAIEiKruM0gPxgJGFCGcVwYZQgBAgISFBkhYYkBEnaUJSyijCigImBgBEcMEsP398c5N7mpvtVV3V3VnUq9n+epp26fe5b33K7ut8457yLbBEEQBEG3MmqkBQiCIAiCkSQUYRAEQdDVhCIMgiAIuppQhEEQBEFXE4owCIIg6GpCEQZBEARdTSjCIFgOkbRI0vz8ulvSeEmfGWRf0yXtM0R5Jkh6fennOSPZTxC0kpVGWoAgCCp5znbPSAtRYgJwJ/AsgO09RrifIGgZsSIMgg4gr6S+lq/nSjpD0j2S7pX05lz+QUl3SbpP0kxJazboc2ru4+eSPlcqH59XovdLOkfSeGB74EpJt+Q6T+f3eyVtmK9HS3pU0qqSjpD0M0kPSPqepJUa9LO6pO/n+rdJensuny7pW3lev5DU09IHGwSEIgyC5ZXXlbZGv1Fx/y+23wlcAhyRy24G3mN7W+DGUnk9vpT72BY4QNIbJa0LfAN4v+1tgBNsXwXcDXzY9i41fVwBfCRfjwPusv034HLb77K9NfAnYP8G/RwDPJ3rnwZ8p3Tv1bZ3AE4C/rnBnIJgwIQiDILlk+ds9+TX5yruX5Xf7wPekq/fDMyW9CBwFPCOBmN8QtK9JOX0dmBTYAfgJ7afArD9vw36+AGwf77+KPDDfL2NpFuzLB9qQpadgO/nMa+pqV811yBoGaEIg6Az+Vt+f4WlZ/1nAV+1vRXwOWDVeo0lbURaMfbmVdhNub6ApgMQ2/4fYA1JGwB7AtflW+cCh2VZzuxPlkKkfsatmmsQtIxQhEGw4rAG8KSkUcAnm6j7f8D/SXoTsHsuvxPYM2+RImntXP4X4DV1+voR8O/AfbYX5rLVgWckrQr8Y6luvX5uK+plC9eHG8gfBC0jvl0FwYrDKcA1wB+AnwIb1Kto+35JvwIeAn4N3JrLn5H0ReAnkgzcDhwJXARcLOmPFed7PwB+Dny8VPYV4B7gt8ADpfJ6/fwncJ6kB0gK+tABzTwIhoAiDVMQBEHQzcTWaBAEQdDVhCIMgiAIuppQhEEQBEFXE4qwzdTEjLxd0ltz+QRJz5TuzZc0Ot8bJ+kOSb/MUUKmF9Z7kh6XtFq+tqSTS2NVxpSU9FlJK+XrsZLuHI65DweSti8irnQbkjaTNLfFfX5I0ialn5d83tpBjkDz0TrlkyvK95E0PV83HUNV0lqSJpZ+ntDuz42kaZLGLo+ydQL5f9WLNf8jd8j36v7vU4q89AtJD+aoSScV///qEYqw/SxxjAbOAz5fundByWm6x/bi7I91EXCk7c2A7YCfAOtV9P1n4BBJqzeQ4bMMk4Vwow9cq7F9t+0vtaq/4stIF/MhYJNGlVqF7f+y/cPGNYfMWsDERpWaodnPuO2Jth9voupatEi2Zhjuv9Eh8mDN/8i7cnmj/30fzj6sOwPvAab0N0gowuFlLdIvsD+OAs6zPR/AiUtsV/lVLSSFuDqsXmeSjgDeCNwlaUYuXkXSxXnFeXap7j/kmI7zJZ1Vp7+TJD2UY0L+Qy6bIOkSSdeRTODfKukWpTiUP5W0daneZZJukPRrSYfk8tH52/PDkn6QV8Fj873DtTRm5QkV8vRKuixffzbP6X5J36you0mW6wFJl0sak8sfl/TlvFJ+l6RT8pgPSfr3UvvH8737Jd0saY1cvmP+5nmPpO+UVizrS7pKKXvEPEkbV/1+VBOTM5fXiyf69tzffdT55ylpHUnX5D6v11KfwMo+S+22B8YD38mfgcLf74SKOW8qaU7u6xpJr6uQ43FJp+Zv5tdL2lkp2syv8lhImpw/o0Ws1P+RdAfwrlI/xfO9G9i3zpwbfXZPBbbK94swbWNrP4u5ry+XfifFZ7T2M97M73au0qp9faX4qfNzn5u1UraaMcdI+u/8vM7W0liuvZKulXQFMEvSa/J8fpaf2ztzvcp5Nfrs5DpvzJ+F+3O9N6pmdZs/E6tleX6SPxePSPp8bX8NaPi/D8D286T/qZ+WpP4qxquNL2ARMB/4FfAU8JZcPgF4Jt+bD1yVy38EjO+nv8eB1fL10yQl9whpxTcd2KdBm7HAS6Rv/aPz2G8D1iGtPFfN9c4H9qvp590kh+tVgPVzv6/Oc/kfUkxISM7URT/bAdeW5vwg8CrSCvfxXP5x4LJ8vTWwOMu5JTCD9IVtNDAb2KpGpt5S2wXAq/L1mhXP4Rrgg/n634ATS8/n06V6a+f3UcB/AzuU6n0yX58FHJ6vHwS2zNc/AKbn68uAnnw9DvhhhUxrl66/DRyQr+cC/5qvvwCcVprDfvn634G5FX1+FzguXx8FnNtfnzVtp1P6DPUz558Ab87X/wT8e53P3YH5+krSZ3sU8EHg0lw+mRTh5lXAY6TP88rAHcDk0vPdhhR9pvx8pwP70NxndyxwZ+nnCVR/Fj8A/Ee+Xo0U1u319P2MN/O7nQtslp/1KblsZfJntFWy1fT1L8AZ+Xo/0ndpSH8nfwLWLX3+x+frjUkxYuvOi+Y+Oz8EJuTrV2UZJwBfq/1flOV5AVg3130I2KjiubzI0v+R84E3NPrfVzz3mr6WzL3q1UlL5E5lSTodpbOQc4G98r0L3Hdbb8m3lvwt+waSsjnR9oyautj+g6RbgQMGINMvbD+ax3iAFL9xM5ISuit/cXoVcH9Nu52AH9l+GXhKKU7lFvne9bb/kq9XIa0qCqX22lIfc5yijyyUNErSyrnfK/J8HpD0y1x3t3zv3vzzq0lK+8E687oXuEjSD4EfV9zvsV2UXwycUbpX3p7bPX8zXw14AynuZbElU457ubGktYBRth/K5ZezdNWyG7BZ6YvoXytk2kbSV4A18+tPpXvlsT5V1Lc9M1/PIGVzqGUnkoIp5nlsgz4bUTvn1+Qxrs5zG039SDCFrA8Cz9p+RSn+aG3w7E2Bh23/AUDSj4Axped7fy4vP9+C99D4s1tF1Wdxd+CDkt6X66wJbJSvy5/xZn63BXcDF0j6O0mx/KLFsj1barcTKWg5tmdKKst1q+1n8vXuwN6STs0/r9XEvBp9dnYEPpbHXgjQ3yKsLI+k60lxbh+rqfOg7fdUNR7g/75+BQlFOLzMJJ3/9ccvSH/UV9l+DujJWwuv6qfNmaSAxc388cPS2I2wNH6jgB/bntRPu9p4kOUP14ul688BjwIHA2Pydb2xR/fTr4CzbZ/ej0xlPkD6Q/4oKRpKb839erIvkV/JMOQ/gHfZflrS11k2TmZt3Mv+nskrwHa2X+lH5nOBfW0/IulYlo0G0yjGZr0/7lbH7aya85NuLl/iy6W25evasWvnogbltWWNPrtV1Pss/qvtS5cZQNqCZT/jzfxuAbA9T9I44B9IKaiOtn1Dq2Srob/f/Ys19d5ffPGoGavevAbz2VnMskdw5b+lWjkHE92l4f8+pTRhBv5Yr06cEQ4vOwG/aVDnu8DhWjbvWn9KENu/JG057F6nSn9xIgvuJK2ENoAl50zr19S5DfiIpJUlrQf0kEJr1bIG8Ie8JzOhwbiQwnh9JI+7FWl1ACmV0D/mVQGS3qI6OfaU4mu+yfYckkHS5hXV7lc+1wQ+QQ4rVsNqpD/05/K4H+xPcNt/yuMX2RL2L92+hXyGkb/Vb0Ff6sXkrMf9kvbL1x+vU2dJ3E7gQKrnWY+GnxXbfwb+JGkvAKX8g5v216YJfgm8I58rrQx8OI/1J+CVvLsAecVRQzOf3Wb+BgDmAIfl3weStlC1AVUzv1vy/bcAT9k+m7RjsFUbZbud/BmU9AHS56teX0eXZCyeb9PzquAOcoxbSa/KXyqfIG1rF2fQ65bqv1fSupJeBexNCgs4IBr978v/L74LnFPsEVcRirD9FHnl7id9eyl/az1Uy5oGv87274FDgHPyIfJtpD+S6xuMcwbwpjr3zgNu0VJjmT7Y/iPpD+OqvF16DbB2TZ2fArNIWyOzgc+UtorKfBc4WsnoYe2K+7X8EPhb3jL7Ammb7c95u/HrwM353iUkRVXFaODSLPtdwIkVdT4D/EuuszHwzdoKTofrF5MU/OWkf7KN+DTwg/y7+iNLDaKOBfbNv/uHgKps7EVMzutYNiZnPT4LTFYy7HmpTp3JwAfyPD9CyuPXLJcDp2pZY5kqDgaOz3O7h/SlaNDkrbTPkbJg/ISl2+GQ/ma+n5/v4xVtm/nsPgv8XMnIpG5OQ6cUULOBuyU9RPqMVK1Cm/ndFvQCDygZOO1E+ny1S7bvAFvksXYnxXqt4lRggzzmw8BBg5hXLZ8hpfZ6gKRQ1yZ9CftL7u9Q4Hel+ncA55D+n5xvu3ZbFJYaERWvvSvqVP3vuzI/o9tJ/w/6/RuIWKPBcoGkMbZflPQ20rZw1YpuuaQku4CpwG22p4+wWEEXomR1PNr23yS9F5hiu3eExeqDpF7gCNvN7IK0nTgjDJYX5mipT9DR/dZc/thfyfx7ZZJhRH9nOEHQTtYkJWdeiXSmd/gIy9MRxIowCIIg6GrijDAIgiDoakIRBkEQBF1NKMIgCIKgqwljmQ7k9a9/vceOHTvSYgRBELSFe+6551nb6wzXeKEIO5CxY8dy9913j7QYQRAEbUHSE8M5XmyNBkEQBF1NKMIgCIKgqwlFGARBEHQ1oQiDIAiCriYUYRAEQdDVhCIMgiAIuppQhEEQBEFX0xZFKKlX0pSasvUkVeWIq9dHj6TtKspPlPSH2v5bJWerkTQ3R4Ivl32pSCIaBEEQjCzD5lBv+2ngtAE06SHJd29N+TRSssV62diXQdLqtv86gHHbju2vAeQMzi/bfmWERRp2xm/Q3PeAq558ss2SBEHQ7Qx5RShpJUnfl3Rzfi+U6zaSrpV0o6S1JY2VdHFus1+uf7ukfXLZhyTdKekmSbuSslL/s6RLyuPZfgZomDtK0haSziJlVEfS63Lf10j6cU4MWa5/uaR5kmZLWiPLPDe3+bakVSTNzD9fXmfMPfIc7pRUzuz8tVw2KdebLmkTUpb0myWdIGndRnMKgiAIWk8rVoQfBh62/QlJJwH7A88Aq9neU9IBJKV2GYCkUcAXgfeRFPG1kmYDJwLjbC/MdaYCK9meNhBhJB0EHAj8HjjXdhGLbCJwju3LJF1b0XSC7b9KmggcADwGzLU9OWcefyvwrO398s9VTAb2ytfXAXPy9ZXA8cAtkqYXlW0/nJX+vsDZkhYC37F9+0DmHARBEAyeVpwRvpWl25d3A5vk6/vy+/xSGcDrgc1JSmI2sD6wDvCE7YUAQ9wqPBJ4Fji7pAQBNgIeKMm0BEmjgTMl3QwcA7wRmAeMknQpcLDtR4EH8wr1c3XGtu0/2/4zsLhUfp/txcATwBtqGiwGZgLnAW8GPljVsaRJku6WdPeCBQv6fQBBEARB87RCEf4GeGe+3h74db7epvT+61L9Z4EHgd1t9+b7C4AN85lZsWpcBIweqDC23wucCUyUNKfYjiSt8LbK11vXNOsBxtgeB3wHEDDa9pdtHwh8QdKqwDdsHwTsU2crc1TeVl2jRvZtsrJ9C/DHolDSWpImk5RuD/Ax28fXmddU29vb3n6ddYYtKHsQBMEKTyu2Rq8ELs6rqaeAM4CdgUWSrgNWI22XvgbSak/SfwA3SDJpW/VoSV8F5kl6ETgFuBOYLmlL28cWg0k6DDgKWFvSa20fXSuQ7YeAYySNIW2TQjKyuULSocArJEW7cr73CLBJlvd3wJPAuyWdnuvMISmx8/IZ6G8oKbQSp5JWuQK+XCr/GPBN4ALbL5d2VtcGfgac2o0GM0EQBMsDshvanbRmIGlT4OvAfNsnlcrXAw6z3ZRFqaQeYJTte2vKTwSOBs4v91+6PwqWKOJZwCTbbTdJlDQX2MP230tl80lzvmcwfW6//faONExBEKyoSLrH9vbDNd6wuE9IWhk4l3QWtkb53jC6VbwamCVpFdIK708DGLMPko4jGQoVXGn7W020+yfgcdv3dLP7RLM062ZRJlwugiAYCG2LLFN2qwAuIlmJ/pQRcqvIRiy7AJ8iKePCrWKMpB9m14kLctmt+X1sYeWZZZiaDVb2s/0t272l17eacZ+wfRHwfLhPBEEQLB+0c0XYKW4Vk4DZtqcW26d1WAeYAjxHOgecWVFnMuE+EQRB0FG0M9Zop7hVvJ20pVrVf9lf8Dnbv7X9Isu6RpQJ94kgCIIOo52KsFPcKh4B3lPqH5KlKyx1t4BkpfomSav3M364TwRBEHQY7dwa7RS3inOBiyR9kqSYP0UyqrkVuKvU/FnS1mcPyU2iinCfaDFh+BIEQbtpq/uEUjzPPfpzl8huFV+0fXidPnoYhLtEPzJNYHBnjLfmVWWlS0Q/7SYDt9qeUyqbm+W+aCAyFIT7RBAEKzIrpPtEmbK7RMmt4vR+mvSwfGahOFZS+TxvIO4TzxdKUNKYfO64QjIY94cysSIMgqDdtOyMUIPIQgHsnd+/3Gp3iZJcy2ShyOwl6XqlLBSrVMku6UxJW0raS9J9tt8r6UJJhbHLWRXuExvmed4mqXzWd3A+lyxWgf+tFNwbYKaksyRt0eyzDoIgCFpHK41lCneJccDPSed/kNwl3g+cQ1JqQB93iV6SshtFcpfYzfZuwC0kd4kzc4zPppF0kFIEmc8AF+b+Cl6wvTdpRfmROrLfTjrT3Al4StJrgHVtV4VWKzgeONn2zsD7JL0xl//K9h7A3yS9p9wgy3URcJxSiqgBzTMIgiAYGq1UhJ3iLlElU5Xst5GU4FuBS0huDc80GLPcz32kjBdV4y2D7Z8BZ5N8FI+s6jjcJ4IgCNpDKxVhp7hLVMnUR/a88ls/j38bafXayNG93M+2wON1xltCVnA3AIcBZxQGORXzCfeJIAiCNtBKY5lOcZcAeF2OWvMSybXhlQrZydcP2n5c0jo0VoRnABcqxTO92vaT2VVi86zsfmf7jmwpW/AKMH5FNZgJY5cgCJZ3BuU+0YxbRD9tNyWtrr5DC90illfKbhelshtIPoUX12nWL+E+EQTBikzHuk80k0Wixl2ih2F0i5A0qpVO69mi9ZRS0WO2D22i3bbAKsCNbXDpWOEYqvtFEAQjR6fsCDU8IxyMW4TqZJEgWYEuBhbSYrcISWtKmpnH/XYumyBpRrYe3VrS5UpZJmYrhUFD0v2SLsrvPblsSu7nLC3NPrHMnGzPq3GfOFTSwdn14zZJxbngSlo2a8V9+Rn8Edghy3OMpDUbzTkIgiBoPc0Yy3SKW8QkYEaWc3VJO+Ty523va3s+MMH2rsDlwAH5/nq57VHAIZLWB7bL/RTpmPrMqUKu0VmmXYCDWLo6LrJW7AqcUG5j+yZStoo/AZdKOldSOb5puf+wGg2CIGgDzSjCTnGLqCfnPbBEUZ2ZDWKOAQofv0dtvwQ8CaxFCoz9UGlulXOSVM5MQWmOi2w/DhQrvH6zVtj+G/ADki/htsButXVyvbAaDYIgaAPNnBEWLgGzSK4Fj+byRm4Re9tenM8FF5PdImy/VHKLWHWgAucIL1sCR0jaDLjc9tSSnD/Pck4DNiNZZUI6kxxje5ykw4Hi8Km8DStSqqR35J+3rjcn97UyWgCMzfPdAHghl68t6U3A/1LjBpId7j+f5f0RyZXkBYIgCIJhoxlF2CluEVNJ24uHAw/YvjMryoJHgE2yzL8jrQD7YPspSfMl3QI8DCyqmhPJsrXcbrGk/yRt+75Sut9f1op1gatsf7FKlqBzDtuDIOhcWpZ9Qg2ySHQSklay/XdJBwAb2/5qi/u/Gdi1YlXZFOE+EQTBikxHuk+ouSwSncRpknYkbel+vKpCXuHuWCo62/aMRh1L+mfgl4NVgkEQBEFraWs+wqA9xIowCIIVmeFeEbYy1mgQBEEQdByhCIMgCIKuJhRhEARB0NWEIgyCIAi6mlCEQRAEQVcTijAIgiDoaoZVEUrqlTSlpmy9nIOw2T56JG1XUX6ipD/U9t9EfxMkTezn/jRJt0rauWrcIAiCoLNpZYb6QdFMHsMaehjGPIbApjm+6YQ64w4JSWNW1Oz0rWAk8xFGeLcg6A7atiJUC/MY5hx/Nyklw21pHsOae1+WNDfLNjavLreWNLPeuLldr6Sry/PK5d/O85mplC9xkzy3myT9v9z8XEkXSHpPk482CIIgaCHtXBEWeQw/IekkUmDuZ0h5DPfMcTwnAZdBn5x/o4BrJc0m5TEcZ3thrjMVWMn2tIEII+kgUoDu3wPn1qRwIucB3MB2r6TNgRNsf1pSr+39ihVhP+MuMy9JN7A028XBwBHAc8BU29OLNE62D8zBwSdlxftD4DzbiwYyvyAIgmBwtPOMsFPyGBZsDvRKmgucDawxwP5r51U1/8tJK8xLgH2KhrZ/CfwXKYXUp8mZPMpEYt4gCIL20M4VYafkMSx4BJhdpITK45dpNG7tvH5Dyj4Paf6/JqV0+rykVYDbSKvejwKfIuUzPMf2cXXkn0paDbP99ttHgNggCIIW0U5F2Cl5DIt790t6Oq8IDXyfrHgyleOWWGZetp+TdEjOa/h/ebzxko4BVgcuzu1eBRxs+3+beahBEARBa2lL9glJvcAetk8qla0HHGb7tJq6lXkMJfUAo2zfW1N+Iinp7fnl/gch41l1FBqSpgNTbD9aKvsQcHOVwqqabzuJ7BNBEKzIdGQ+wmaocpNokMewhza5SUgaVU8J9sOHgIckLQZ+XHPvGwPsq5BjZYAwjKnPSLpPrOiEe0gQJIZsLDMUNwlgHnC67eva7Sah5Dg/Q9IsksHKrbl8vKR7JE0tyjLHKjnSnyxpQ5JxyyXAJNu95RewLfAmSXMknZ/7XTO7Tdws6du57MOSfpqfyQeANYEbJZ0uaezAn34QBEEwVFqxIuwkN4nnbR+Q6xVlxwPjgLWAuaW6c20fJ+ku26fk879ltktr+JXtCZLOzj6BuwAzbH9PKTrNDvnZfNz245Jk25LGAb3AFEmrA9NsXzOQOQdBEASDpxXuE53kJnFPRf3Ftl+0/WRuV/BQfl/Y5LjNuE9MAU7KZ5CbADhxE0nxrwIcXNV5uE8EQRC0h1YowsJNApa6CUBjN4nd87biNiTXgQ0lrQZLVo2LgNEDFcb2e4EzgYl5q3JS6XaVgh0laXVJbyQp6SVd1dRrJE+V+0Ttc3nC9kSS0vu8pFUlfUHSPOADwLG2D6QC21Ntb297+3XWWacfMYIgCIKB0Iqt0Y5yk6jg34CbSSu5Z/qpdz3wXUk/sP1fFfc3V4om8zvbd0j6BXCppMOBB2zfKemMvG36auALwBjgSWBP2y83kLMrCYOOIAjazYDdJwbiGlHTbombRLtdIyrG3gcYbXtWqayXfDZn+++SNgC+B/w2n/XdmleXzfQ/GbjV9pxWydwf4T4RBMGKTEe6TzTKIFHhJtHDMGaQsH1dP7c/KulI0ursdGB8gzF3Ja1YCx4DnmhC3Kq+VgNeHuKZ6ApNuE90JrGSDzqJfs8Ih+IaoVIGCWBfkiHI8W10jbhU0ixJV0k6MsswrXR/Yr4+X9Ic4JN5zMtIbhwLSSvE2rE2kTRb0jxJJ9meV+M+cSgwFvhIHvPU3G7D/Hxuk3R8LjtaS11EtgM2Bm6WdIKkdRvNOwiCIGg9jYxlCteIcaSA0Pvn8tVsvx84h6TUgD6uEb0kZTeK5Bqxm+3dgFtIxiJn2j5oIMJKOkjJD/AzwIW5v4IFtvcFns7yjSMZ4Kxdav9ukpXoHmQDHknrA++2vQvpXLKW00jbvrsCW0h6Ux3xbstjbpe3WY8HTra9M/C+bIzzwdJzuM/2w8CupGd7tqRLJO00kGcSBEEQDI1GirCTXCMKd4c/1Fy/tlRn45LshSvFW4AHasrKbAp8TykG6eZAvb26ot8HgY1Y9tndl8tOJim8qcAbAGwvBmYC5wFvJinLPoT7RBAEQXtopAg7yTXCda5Vun6sJPu2+f0JYKuasjKPAJ/I83kn8LM64hX9bgk8zrLPbttcNt/2BJLj/gRJa2VDm3mkc9OP2T6+qvNwnwiCIGgPjYxlOt01orbtXfn88AaSAvyt7aeUQqzdAtxf0exE4HxJq5IU+P7AXyrq7SrpKGCe7d9LOgO4UCnl0tW2n5R0oaSNSOmcDgXWJinWU8NgppowugiCoN20JPuE6mSQ6BZUka2inYT7RBAEKzId5z5R4RqxQqMUO/XIUtEdIyVLEARBMHSGrAhzCqFxLZClI7A9A5gx0nIEQRAEraEVsUaDIAiCoGMJRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1YQiDIIgCLqaUIRBEARBVxOKMAiCIOhqRkQRSuqVNKWmbL2cmLfZPnpyKqPa8hMl/aG2/1aS5Z88hPaTJe3RQpFWXKTl8xUEwQrDcrMitP10fxnuK+gB+ihCUnLfptM7SVq9omxYnouklXNkniAIgmCEaPs//FYl95X0oVJS23Yl952R8x1uLenLkuZm+cbmOssk9a3T75ElOTetStBbYk3gRkmnF2MEQRAEw8twrHw6Kbnv8zm572Jgg5x66WjghKqkvhV9vwH4GLBz7vdXVCfoBcD2s6TwdD8Bpkj6kaQP1Ok78hEGQRC0geFQhJ2U3LdIzLs50JuT8Z4NrEF1Ut9aNgLuzcl2CzmrEvQuwYmbSIp9FeDgqo4jH2EQBEF7GHLQ7SYoEtTOIiX3LVIVNUruu7ftxfkMbTE5ua/tl0rJfVcdqDC23ytpS+AISZsBl9uemm8XCvYRYHaRKzHLsB1QrB6rEvgWc91W0qicm3FUaf4353ZnFZVzjsNjgPGkLBbH2n5soHMKgiAIBs+gV4QDsPy8EtgiJ/fdCrgily+SdBvwL6TVELBkFfUk8FdJjwPfzGVFct8bgV1IyX0Pzud8ZRkOA74OHCTpO1Wy237I9jHAB6k4T7R9P/B0PiO8CTjU9l3Aqjmp79vr9Lsgz+/23O5tpGTGp0q6HZhr+0mSoc/7gTF5rnva/lIowQrs5fMVBMEKw6AT80rqBfawfdKgB5cmACvZnlZO7itpXeAdwO7N9C9pddt/baLeqOUhE3zNvMfYfnEg7bsqMe+l4aoQBA05cMX6cjbciXmbWhEOg+XnpaTkvlfAkCw/15Q0M4/77VxWaw16uaR5kmZLWiPXuV/SRfm9J5dNyf2cpZSBvs+cJF2QV43Fa9faOVbJVMPMPMYWzfwugiAIgtbS7BlhYfn5CUknkSw/nyFZfu6plLV9EnAZ9LH8HAVcK2k2yfJznO2Fuc5U8spoIEJLOgg4EPg9cG7J6GUSMMP29yRNk7RDLn/e9gG57QTbf5U0ETiApIDXA3YgneUdIukZYDvb4/Lc3l81J9u718g1CrirZo5fqCMTALZ3k/Qu4DhJbwIusb2MS0gQBEHQPpo9I+wUy896ct4DIGk0cGY+rzwGKFwZHrX9Eum8bi3gLcBDpblVzknqE2Kkao71ZFqC7Z+RrFOfy3PrQ7hPBEEQtIdmFWFh+QjJ8rOw8mxk+bl79sXbBlhAtvyEJaunRcDogQpt+73AmcBESXMkFX6I9eQslG4PMCb7NH4HKBRZeRtWwBOkM0qArevNyX0PWKvmWE8mcp1J2QDnMOCMPLeqOYf7RBAEQRtoVhH2Z/l5HXAUfS0//wO4IVtPDpfl51TgHyXdAvzN9p01zR4BNskyv7veZG0/BczP/ewBLKqaU0W7qjk2kukVYLztY2w/RBAEQTCsDNpqtLIz6ZPA521vWypbDzis2Tii2VhllO17a8pPJEV5OX8olqrNImkl23/PZ4Qb2/5qC/ueDNxqe85g2neV1WgQBF3HcFuNtsyhXsnp/IukMGpLsP00MNBg2iux9FytYBpwO7B7bYM68gzVpeI0STuSnPk/XqftV4EdS0Vn257RjHy5/coAthc126bb0Ckj7z7hk1cs0/QgCJZlKA71y7hUkLYnjwNe0yKXilYF035d7vsaST9WCgTQK+kqSVcDe0uaKOmW/CoyWvyKdF64EvDm3Ncybha2T7DdW3rNUATdDoIg6CiGsiLsFJeKicA5ti+TdG2pySq295H0epKl5jjgtcD52bVifLkM+BA1bhYstSgtZCgH3V6c53MWKej2LZKul/S9or7tZyWNIwUXn6KUEmqa7WsGMvcgCIJg8AxFEda6BbyTpAjLLhV7luqX3Q8A3kCFu0Ffj4SmOZJkkXm27fml8o2Aq0syFRSyb0yyar2pdK+qDLKbhaTCzaKWPkG3JTUMug3cJGkxKdzcwUAfRZgtYycBbLjhhhVDB0EQBINhKNknOsWl4jGSpSssdYWApS4VjwE/K7Y3Scq7qgz6ulnUsiTodmk+5ee0LfD4kg6kVSV9QdI84AOkoNsH1plfuE8EQRC0gaGsCK8ELs4uFU+RgkvvzFKXitVI26WvgSWro8L9wKRt1aOzwck8SS8Cp5BcKqZL2rLI/gBLXCqOAtaW9FrbR9cKlN0PjpE0hrRNCsnI5gpJh5KU3yJg5VKbBZJm5XksBm60/ZXaMuArjR5I7qsIur0QOCI/lwslrQJcbfvJ0qq3HHT75Ub9dyNhqBIEQbtpqftE5QApmPbXgfllt4fhcqsoVmdZEc8CJmVlNIGas0i1IJB4M4T7RBAEQX061n2iiuwecC4wk5TcdgnD6FbxamBWXpHNAf40gDH7RdIFLHvmd7LteQNoP6zuE4M/fh05IuNREATtpuUZ6stuFcBFJCvRn9K6TBUDcquw/WfbuwCfIinjWaXbe2VLzh9nRVnMoSxbb17BUetmYfvQGveJeeE+EQRB0Fm0Y0XYKW4VAC/Y/nhWUB8Bnu6nn9dT7VJRrhPuE0EQBB1Gy1eEdE6miv5kqrIOLbtU/Igm3SdY9nlUuk/Yvomk6FchuU/0QZF9IgiCoC20QxF2iltFfzK9QHKeh6WuF/VcKsqE+0QQBEGH0Y6t0U5xqwB4Xd6GfYm0pbljrv+8pN9KmgM8Cjxd5WZBjUvF8u4+EYYnQRAEfWm7+0TdgZNbxRdtHz4iAnQw4T4RBMGKzArlPlGPklvF6SMxfqsYqvtEEARBMPKMiCLMfnPjRmLsVmL70JGWIQiCIBga7TCWCYIgCIKOIRRhEARB0NWEIgyCIAi6mlCEQRAEQVcTijAIgiDoakIRBkEQBF1NKMIgCIKgqwlFGARBEHQ1oQiDIAiCriYUYRAEQdDVhCIMgiAIuppQhEEQBEFXE4owCIIg6GpCEQZBEARdTSjCIAiCoKsJRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1bRFEUrqlTSlpmw9SScOoI8eSdtVlJ8j6TZJt0rautVythpJcyWtVFP2JUkbtHPcFYUNxm+wzCsIgqDVrNS4Smuw/TRw2gCa9JDku7em/Gu2H5P0NuBrwP79dSJpddt/HYis7cb21wAkrQa8bPuVERYpCIKgaxnyilDSSpK+L+nm/F4o120kXSvpRklrSxor6eLcZr9c/3ZJ++SyD0m6U9JNknYFJgH/LOmS8ni2H8uXi4DF/ci1haSzgFn559flvq+R9GNJvTX1L5c0T9JsSWtkmefmNt+WtIqkmfnny+uMuUeew52S9ijd+loum5TrTZe0CbAxcLOkEySt28TjDoIgCFpMK1aEHwYetv0JSSeRVmjPAKvZ3lPSASSldhmApFHAF4H3kRTxtZJmAycC42wvzHWmAivZnlZn3K8C364tlHQQcCDwe+Bc23fnWxOBc2xfJunaiv4m2P6rpInAAcBjwFzbkyUJeCvwrO398s9VTAb2ytfXAXPy9ZXA8cAtkqYXlW0/nJX+vsDZkhYC37F9e8W8JpGeIxtuuGGd4YMgCIKB0oozwreydPvybmCTfH1ffp9fKgN4PbA5SUnMBtYH1gGesL0QoNFWoaTPkpTvrRW3jwSeBc4uKUGAjYAHSjKV+xsNnCnpZuAY4I3APGCUpEuBg20/CjyYV6ifqyOabf/Z9p9ZdrV6n+3FwBPAG2oaLAZmAucBbwY+WKfjqba3t739OuusU2f4IAiCYKC0YkX4G+CdpC3I7YFHc/k2pfdfl+o/CzwI7G17saSVSUpjQ0mr2X4prwgXAavWDiZpL2An0qqtD7bfK2lL4AhJmwGX255KWuFtBTwMbA1cX2rWA4yxPU7S4cAGwGjbX85jzs/bod+w/UrePr3E9jM1w4+StEa+Hl0q30bST4G3AH8szWUt4LPA7qQV5Mcq+gyCIAjaSCsU4ZXAxXk19RRwBrAzsEjSdcBqpO3S1wDrAqcC/wHcIMnA4yTl+VVgnqQXgVOAO4Hpkra0fWxpvKnAi8BNkh6x/WlI1qTAloCBo2wfI2kMaZsUYBpwhaRDgVdIinblfO8RYJMs7++AJ4F3Szo915lDUmLn5TPQ31BSaCVOJa1yBXw5l/UAHwe+CVxg+2VJW+Vn8QrwM+DUMJip5smrnhxpEYIgWMGR7eEZSNoU+Dow3/ZJQ+hnAhVnh5I2KluT2t6/5v4oSNuukmYBn7FdXqm2BUlzgT1s/71U9n3SOelzDMJqdPvtt/fdd9/duOIKQLhMBMHg6OQvkZLusb39cI3XNof6GmvSy4BzgZsZOWvSV5NWnA+Qzumm5f7HSPphthi9IJfdmt/HFsYtWYapku7Och6XrUqL13HNWI1K+ifSivlVhNVoEATBiNNOP8Jaa9IrSdake46ENSnwD8CfSWeEZWvSScBs21OLVWMd1gGmkFZxs23vDHyrXCEr0H6tRoHePMcBWY0GQRAE7aGdIdY6xZr07cDtdfovu0k8Z/u3tl+kvv9i26xG82rybkl3L1iwoM7wQRAEwUBppyIsrEkhWZMW53GNrEl3t92b7y8gW5PCklXjIpa1yCTfK6xJK0Om2X4vcCYwUdKcwrmdZCjznlL/kAx8IFmZFqwt6U2SVq8aPzNKyRl/DfpajY6mwmpU0mSSq0YPyWr0+Dryh/tEEARBG2inIrwS2CJbk24FXJHLC2vSo0jbnMCS1VhhTXoT8M1cVliT3gjsQrImPVgpakyZs0i+gjdlC9I+2H7I9jGkVVdhJXQu8H5J88jnhsCsvM25a6n5sySH+ZtJlrFVFFajPyFZvhZ8jLTqvMj2y6XytUlWo7vaPi1cJ4IgCIaftlqNKoUx26NsJSppPeAw26flnzcFvmj78Dp99ACjbN9bU17rLvFARfOq/ibQ/xljvXa35lVlpSVoP+0mA7fanlMqmwucb/uigchQ0E1Wo0EQdB/DbTU6bEG3C8rBt5Wc6c8FTu+nSQ/LZ/DtYyWVz/OutP2turWXyvFPwPOFEpQ0Jp87BhWMlPtEJ5ueB0EwMFq2NapBBN8G9s7vX26Du0Qh1zLBtzN7SbpeKfj2KlWySzpT0paS9pJ0X45Yc6GkwtjlLNu9pde3JG2Y53mbpPJZ38H5XLJYBf63UkxTgJmSzpK0xQAedxAEQdAiWnlGWLhLjAN+ztIV2mq23w+cQw4aDX3cJXpJym4UyV1iN9u7kdwNpgJn2j6ozrh1g28rO84DF+b+Cl6wvTfp3O4jdWS/neTvtxPwlKTXAOvaroooU3A8cHJ2rXifpDfm8l/Z3gP4m6T3lBtkuS4CjlPKjFFvnkEQBEEbaKUi7BR3iSqZqmS/jaQE3wpcQjKwaWTMUu7nPpLxTtV4y2D7Z8DZJB/FI6s6DveJIAiC9tBKRdgp7hJVMvWRPa/81s/j30ZavTZydC/3sy0pjmrVeOV5TJJ0A3AYcEZhkFMxn3CfCIIgaAOtNJYZSPDtIuZnOfj2w7aPltRs8O2zSJFilgm+Xcb2Q0Bt8G2A1+WoNS+RXBteqZCdfP2g7cclrUNjRXgGcKGkVYCrbT+plLpw86zsfmf7jmwpW/AKMD4MZqoJo5UgCNrNoNwnmnGL6KftpqTV1XdooVvE8krZ7aJUdgMpE8XFdZr1S7hPBEGwItOx7hNlt4h61LhL9DCMbhGSRrUy1VG2aC07zT9m+9Am2m0LrALc2AaXjuWCVro8xIowCIJ20/CMcDBuEaqTRYJkBboYWEiL3SIkrSlpZh7327lsgqQZ2Xp0a0mXK2WZmK2cQFfS/ZIuyu89uWxK7ucsLc0+scycbM+rcZ84VNLBSq4ft0kqzgVXUilrhe378rz+COyQ5TlG0pqNfhdBEARB62nGWKZT3CImATOynKtL2iGXP297X9vzgQm2dwUuZ2mG+/Vy26OAQyStD2yX+ynSMfWZU4Vco7NMuwAHsXR1XGSt2BU4odzG9k2kbBV/Ai6VdK5S0t4+hNVoEARBe2hGEXaKW0Q9Oe/JfY4GzswGMccAhY/fo7ZfImWlX4sUGPuh0twq56RsBVOimOMi248DxQqv36wVtv8G/IDkS7gtsFttnVwvrEaDIAjaQDNnhIVLwCySa8GjubyRW8Tethfnc8HFZLcI2y+V3CJWrR2s5BZxQO09SG4RkrYEjpC0GXC57aklOX+e5ZwGbEayyoR0JjnG9jhJhwPFQVbZWkikVEnvyD9vXW9O7mtltAAYm+e7AfBCLl9b0puA/6XGDUTJ4f7zWd4fkVxJXiAIgiAYNppRhJ3iFjGVtL14OPCA7Tuzoix4BNgky/w70gqwD7afkjRf0i2kJL6LquYEHF3TbrGk/yRt+75Sul9kreghZacosy5wle0vVsnSqYSBSxAEnUTLsk+oQRaJTkLSSrb/LukAYGPbX21x/zeTUi8N6uGH+0QQBCsyHek+oeaySHQSp0nakbSl+/GqCnmFu2Op6GzbMxp1LOmfgV8OVgkGQRAEraWt+QiD9hArwiAIVmSGe0XYzgz1QRAEQbDcE4owCIIg6GpCEQZBEARdTSjCIAiCoKsJRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1bQyQ31DhpLQt1S/hxYm9JU0AVjJ9rQ694uYpccDC2vHDdpLK3MbDoQIExcE3cOIrwhtP92sEsz0ANtVlH/N9s7AocDJjTqRtHqT422aM8y/rc64QyLHSw2CIAhGiLYpwlYm9M3Jbm9Sygrf0oS+Nfe+LGlulm2spCmkhL4z642b2/VKuro8r1z+7TyfmUqJgzfJc7tJ0v/Lzc+VdIGk9zT/dIMgCIJW0c6t0SKh7ycknUTKUPEMKaHvnjmg9STgMuiT/HYUcK2k2aSEvuNsL8x1ptLPVib9JPQlZar4PXBuTS5DckLcDWz3StocOMH2pyX12t6v0RZq7bwk3cDStE8HA0cAzwFTbU8v8hnaPjBnyZiUFe8PgfNsL6qRb1J+Xmy44YZ1RAiCIAgGSju3RjsloW/B5kCvpLnA2cAa/Y1VQe28quZ/OWmFeQmwT9HQ9i+B/yLlUvw0OaVVmUjMGwRB0B7auSLslIS+BY8As4vciHn8MpXjlqid12+AvXLZ9rlske3PS1oFuI206v0o8ClSYt9zbB/XzxhBEARBi2mLIszWoT3AW0sJfaeTEtQ2m9D3j6QkwLUJffcDPiDpZGCfknXoQBP6Xk3aZi3u3S/p6bwi3BT4T6BsxPMa4JCKRMIFy8zL9nOSDskJfv+PtC07XtIxwOrAxbndq4CDbf9vg8falYT1ZhAE7aYtaZiq3CT6qVuZ0LfemZykjWw/JultJEvR/Rv0v7rtv9aUjepvm1XSdGCK7Uf7Kyvd66XJ+da0Wxmg9jywEd2Uhmm43SdC8QbByNNxaZiGaB16B8k45Ip2W4dKmiBphqRZpHO6W3P5eEn3SJpalGWOlXSrpJMlbUg607tE0r9my9IlL9K53j9ImiPp/Nzvmtla9GZJ385lH5b00/xMPgCsCdwo6XRJYwf3GwiCIAiGQiu2RodsHUoyjrmL9luHPm/7gFyvKDseGAesBcwt1Z1r+zhJd9k+JW97FivCr9SMORl4yPZpks7OrhC7ADNsf0/SNEk75GfzcduPS5JtSxoH9AJTlHwbp9m+ps6cgyAIghbTCqvRTrIOvaei/mLbL9p+MrcreCi/L+xPlhLNWI1OAU7K26ybADhxE0nxrwIcXNW5pEmS7pZ094IFC5oUKQiCIGhEKxRhYR0KS60jobF16O62e/P9BWTrUFiyalwEjK4drGQdOqVKmBwF5kxgYt6qnFS6XaVgR0laXdIbSUp6SVc19SrlKVFlNVr7XJ6wPZGk9D4vaVVJX5A0D/gAcKztA+vMK9wngiAI2kArtkavBC4uWYeeAexM89ahD9s+WlKtdeidwPQKK82BWodWKpYS/wbcTFrJPdNPveuB70r6ge3/qri/uZIT/e9s3yHpF8Clkg4HHrB9p6Qz8rbpq4EvAGOAJ4E9bb/cQM4gCIKgDQzYarTKQlJNBM4uW4eqxYGzm5B5H2C07Vmlsl7y2Zztv0vaAPge8FvbEyTdmleXzfQ/GbjV9pxWyNuIbrIaDYKg+xhuq9GW+BHafpplfe6WIbsJnAucnot68ti1mRy+VnaNIK0k61LlGlFHvuv6uf1RSUeSVmenA+MbjLkracVa8BjwRCMZ6vS1GvByozPRbmaksk8EQX+Em82KRb9nhEN0jVgSOBvYl2QIcnwbXSMulTRL0lWSjswyTCvdn5ivz5c0B/hkHvMyYB7JKKa3YqxNJM2WNE/SSbbn2e4tvQ4FxgIfyWOemtttmJ/PbZKOz2VHa6mLyHbAxsDNkk6QtG5/v4sgCIKgPTQylilcI8aR4mAWK7TVbL8fOIccCBr6uEb0kpTdKFLg7N1s7wbcQjIWOdP2QXXGresaoeQH+BngwtxfwQLb+wJPZ/nGkQxw1i61fzfJSnQPsgGPpPWBd9vehXQuWctppG3fXYEtJL2pjsy35TG3y9usxwMnO6WGel82xvlg6TncZ/thYFfSsz1b0iWSdqrTfxAEQdAGGinCTnKNKNwd/lBz/dpSnY1LsheuFG8BHqgpK7Mp8D0lx/nNgXp7dUW/DwIbseyzuy+XnUxSeFOBNwDYXgzMBM4D3kxSln0I94kgCIL20EgRdpJrhOtcq3T9WEn2bfP7E8BWNWVlHgE+kefzTuBnVbKV+t0SeJxln922uWy+7Qkkx/0JktbKhjbzSOemH7N9fFXn4T4RBEHQHhoZy3S6a0Rt27vy+eENJAX4W9tPKYVYuwW4v6LZicD5klYlKfD9gb9U1NtV0lHAPNu/l3QGcKFSpomrbT8p6UJJG5GyWBwKrE1SrKeGwUw1YZQQBEG7aUnQbdUJnN0tqJ+A3O0g3CeCIFiR6Tj3iQrXiBUapdipR5aK7hgpWYIgCIKhM2RFmFMIjWuBLB2B7RnAjJGWIwiCIGgNrYg1GgRBEAQdSyjCIAiCoKsJRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1YQiDIIgCLqaUIRBEARBVzMiilBSr6QpNWXrSTpxAH305FRGteXn5NRHt0rauhXyVozRm2OEDrb9ZEl7tFCk9iKN3CsIgqDNLDcrQttP95fhvoIeoI8iJCX33ZkUy/PkRp1IWr2ibFiei6SVc2SeIAiCYIRo+z/8ViX3lfShUlLbdiX3nZHzHW4t6cuS5mb5xuY6yyT1rdPvkSU5N61K0FtiTeBGSacXYwRBEATDy3CsfDopue/zObnvYmCDnHrpaOCEqqS+FX2/AfgYsHPu91dUJ+gFwPazpPB0PwGmSPqRpA/U6TvyEQZBELSB4VCEnZTct0jMuznQm5Pxng2sQXVS31o2Au7NyXYLOasS9C7BiZtIin0V4OCqjiMfYRAEQXsYctDtJigS1M4iJfctUhU1Su67t+3F+QxtMTm5r+2XSsl9V60drJTc94AqYWy/V9KWwBGSNgMutz013y4U7CPA7CJXYpZhO6BYPVYl8C3muq2kUTk346jS/G/O7c4qyboqcAwwnpTF4tjS1m4QBEEwDAyHIuy45L6275f0dF4RGvi+7am1SX0r2i2QdAVwu6SFwBF5vrUJeosmY4AngT1tv9z0Ex1uWpCzMgiCYHll0Il5JfUCe9g+qVS2HnBYs9afknqAUbbvLSf3lXQOsCVJCR1l+4FBCbmcImkCsJLtaYNp31WJeS9dTl0oDowvB0HQLoY7MW9LzwgH6wJRSu57RS4fsgtEnXotna+kC7JlafHadRB9jGmlTEEQBMHAaEoxtNsFAphue5zt62BILhBrSpqZx/12Lqt1i7hc0jxJsyWtkevcL+mi/N6Ty6bkfs6SNL1qTrYPtd1bes2rnWOVTDXMzGNs0czvIgiCIGgtza6QOsUFYhIwI8u5uqQdcvnztve1PR+YYHtX4HKWGtSsl9seBRwiaX1gu9zPrfXmVCFX1RzryQRArncRcJykayRVPotwnwiCIGgPzSrCTnGBqCfnPbnP0cCZ2XDnGKDw6XvU9kskw5W1gLcAD5XmVjknqU8MsKo51pNpCbZ/RnLTeC7PrQ/hPhEEQdAemlWEhQsAJBeIwt2hkQvE7tkpfRtgAdkFApasnhYBo2sHK7lATKm9B8kFAjgTmChpjqRiNVpPzkLp9gBj8ursO0ChyMqWDyJZhb4j/1zEK+0zJ/e1NKqaYz2ZirlOypaohwFn5LkFQRAEw0Sz7hPNukDsSVIQZReIlYHRtt/TjAtEPqObSlIqS1wg6liS1rpATAUulXQ48IDtO5V8BQseATbJMv+OtALsg+2nJM2XdAvwMLCoyq2DFHWm3O6VijlWyfQlllXS422/2OTvorsI68wgCNrMoN0nKjuTPgl83nY9h/Nm+phAhWuBpI1sPybpbSSr0v0rO1haf3Xbf21ivFFV27SSVrL9d0kHABvb/urAZtLvmJNJZ4/zAGwvGkj7bnKf0CnLqftEELQBnxxf/GD43ScG7VCfLUe/B2xAWlkdSjImWSjpWlLUl4+SwpNNsX2wpP2Af8njnmr7OkkfAr4ELAQmk4xLXidpt7IRzUAsSUmO7FsCu0l6HfDD3P8i4Bu56udJ26DflbQBcEguP872vcDVknYirUA/kvu+H7iftNV7CMnYZsfS8GcDa+d7hUP9QmB6fh5X2T6jVH9N4Mq88pxq+/F68wqCIAjaw1AiyxSWpJ+QdBLwQeA44ETb788rqUnAZdDH6nIUcK2k2SQry3G2F+Y6U+nf2byuJSlpi/T3wLklI5qJwDm2L8sKumAV2/tIej3JQGUc8FrgfEkTSUpzraIMuJFkXboD6czvENufq5HhDXm+O+fwcKNIkW5Otn2LpOslfa+ob/tZSeNIVqhTlPwhp9m+ps7cgyAIghYzFEVYaw35TuAZlrUk3bNUv2x1CfAGKqws+xpiLqUJS9JfkyxJ55fKNwKuLslUUMi+MWmFd1PpXlUZZOtSSYV1aS19gm5Lahh0m3QWupi0Wj4Y6KMIs0HQJIANN9ywYuggCIJgMAxFEXZKMO3HgK1Ixi1bA9fnJsW54GPAz2x/NI+zMknJ1ZZBX+vSqmeyrdoQdDvPZSqkM8KqOkEQBMHAGYoi7JRg2tOAKyQdSlJ+i4CVS20WSJqV57EYuNH2V2rLgK80eiArbNDtIAiCFZiWWo1WDpCCaX8dmN+qAN015f0G6M6rskIRzwImZWU0gZqzSFUEEm8HhdWo7TmN6lbRTVajQRB0Hx1jNdoMWhpMeybJenQJtp8GBhqgeyWWnrcVfK3sVsHS8G8FrwZm5RXZHOBPAxizXyRdwLJnfifbnjeA9ivDwN0nuol+jozbQmScCoLuo+UZ6lUK0E2Kofk+4Ke0KEC3pEvK4zVyq7D9Z9u7AJ8iKeNZpdt7ZUvOH2dFWcyhLFtvXsEhaaKkW/JrO1cH3T6yJPemkjbMc75N0vE14q0J3CjpdEljB/O8gyAIgqHRjhVhrVvF/iRr0tVs77kcuVUAvGD741lBfQR4ut6kspvFeEpuFsCHauq8AfgY4T4RBEHQMbR8RUjnBOjuT6Yq69CyS8WPaNJ9gmWfR6X7hO2bSIp+FZL7RNUcI/tEEARBG2jHirBT3Cr6k+kFkvM8JNcLqHazqJp7uE8EQRB0EO1QhJ3iVgEplNts4CXSluaOuf7zkn4raQ5JkT9d5WZBjUtFuE+0njBeCYKg3bTdfaLuwMmt4ou2Dx8RATqYcJ8IgmBFZoVyn6hHya3i9JEYv1UM1X0iCIIgGHlGRBFmv7lxIzF2K7F96EjLEARBEAyNdliNBkEQBEHHEIowCIIg6GpCEQZBEARdTSjCIAiCoKsJRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1YxYZJlg8EhaADwxwGavJ8V17TRC7uGjE2WGkHs4GS6Z32J7nWEYBwhF2DVIuns4Qxa1ipB7+OhEmSHkHk46UeZmiK3RIAiCoKsJRRgEQRB0NaEIu4epjassl4Tcw0cnygwh93DSiTI3JM4IgyAIgq4mVoRBEARBVxOKcAVG0mskXS3pNkn/VHH/akm3SLpB0ptGQsYaeb6R5flWTfkbJd0o6XZJe4yUfPXoR+6TJd2RX7uPlHxV1JM535Ok+yVNHAnZ+qOfZ72apPPy5+SskZKvHv3IvaukuyTdKemIkZKvivx3d6+klyStVHFvuf2bHCihCFdsDge+T8r9OFHSKjX3P2N7F+BrwOeGW7gykrYDxmR5VpH0rtLtLwEnAXvl9+WGBnJfZHtH4P3AySMiYAUNZAYYD/xx+CXrnwZyfwa41Pb7bB87MhJW00DuLwAfA3YClrf8pv8L7A7cWXFvuf2bHAyhCFdsdgTm2F4M3A9sWr5p+7F8+Xdg8TDLVsuOwJx8PQd4T+ne1sAdtv8C/J+k1wy3cP1QV+7S8/0bsDwdxvf3rAE+AcwYVomaoz+5e4HxkuZKGj/cgjWgP7l/DqwJrAq8OMxy9Yvtl2z/qc7t5flvcsCEIlyxWQv4c75+AXhtbQVJo4ETgXOGT6xK1qK+rKO91Kqrch4jyFo0eMbAZEb++ZZZizoyS9obmEf6crS8sRb1n/VbgVnAvsC/1m7ljTBrUV/u/wZmAr8ELhlWqYbG8vw3OWCWpw9LMEgkrQdcVlP8NPA8sAbwUn5/vqL510lbeL9uo4jN8DxJRugra3m1Wm8eI8Xz1JcbSR8GXmf70uEVq1+ep77ME4FPAv84vCI1xfPUl/sFYJ7tv0l6FFgXeHJYpavP89SX+0zgvcAzwE8kfd/2X4dVusGxPP9NDphYEa4A2H7adm/N6x+BO4Dd86qvB3ik3E7SYam5Lxp+qftwB+k8AmAPlj2XeEDSjpLGAGvY/nOf1iNHXbklbQ0cnV/LE/0967eRVilfAD4rabPhFa1f+pP7dmDr/FkfCywYXtH6pT+5FwPP234ZeAVYeZhlGyzL89/kgAlFuGIzDTgIuAU4P39b7skKEOC7wPb5XOWUEZMSsH0v8JKkW4BXbP+0ZP33b8BppPOV00dKxioayH0maWVyvaQfj5iQNfQns+0e2/uQdgq+afuXIylrmQbP+gzSZ+Q2YFpWLMsFTcg9R9IdwE22XxgxQWuQtLKkOcA2pM/wDp3wNzkYwqE+CIIg6GpiRRgEQRB0NaEIgyAIgq4mFGEQBEHQ1YQiDIIgCLqaUIRBEARBVxOKMAiCIOhqQhEGQRAEXU0owiAIgqCr+f9EuwJ0qnAtNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not(minimal_mode):\n",
    "        ##Qualitative testing\n",
    "\n",
    "        #sample sentences for model analysis\n",
    "        test_sent = [\"BEGIN on the middle is a green glass and that is a orange bowl END\", #0\n",
    "        \"BEGIN and on the middle is a green glass and that is a orange bowl END\",\n",
    "        \"BEGIN a blue bowl is on the right and on the right there is the blue bowl END\",\n",
    "        \"BEGIN on the middle there is the orange and the orange on the middle is orange END\", #3\n",
    "        \"BEGIN the orange is orange and on the middle there is the green cup END\",\n",
    "        \"BEGIN on the left there is a blue glass and this is a orange END\",\n",
    "        \"BEGIN the glass on the left is blue and the bowl on the right is green END\", #6\n",
    "        \"BEGIN the orange on the right is green and there is a blue cup on the middle END\",\n",
    "        \"BEGIN on the right there is a red glass and the cup on the middle is red END\",\n",
    "        \"BEGIN a green glass is on the right and on the left is a orange END\"] #9\n",
    "\n",
    "\n",
    "        outputs, vision = test_with_sentences_ESN(test_sent, reservoir, nb_concepts, threshold_factor)\n",
    "\n",
    "        #plot final outputs on the first test sentence\n",
    "        id = 4\n",
    "        plot_final_activation(outputs[id][-1], concepts_delimitations, output_id_to_concept_dict, nb_concepts, test_sent[id])\n",
    "\n",
    "\n",
    "        #plot and save to png the evolution of the outputs during the processing of the first test sentence (plots developped by Alexis Juven)\n",
    "\n",
    "\n",
    "        id = 4\n",
    "        s = test_sent[id]\n",
    "\n",
    "        if continuous_sentence_training:\n",
    "            output_fun = lambda x: x\n",
    "        else:\n",
    "            output_fun = sigmoid #sigmoid function is recommended when dealing with final learning\n",
    "\n",
    "        plot_concept_activation(s,\n",
    "                                outputs[id],\n",
    "                                concepts_delimitations,\n",
    "                                nb_concepts,\n",
    "                                savefig = True,\n",
    "                                sub_ttl_fig = s+ \" ESN CL\",\n",
    "                                output_function = output_fun)\n",
    "\n",
    "        '''\n",
    "        ##reservoir activity visualisation\n",
    "        res_states, vis = test_with_sentences_ESN(test_sentences, reservoir, nb_concepts, 1)\n",
    "        s = test_sentences[500]\n",
    "\n",
    "        res_act , _ = get_int_states(reservoir, [s], one_chunck = False) #get reservoir states\n",
    "\n",
    "        plot_hidden_state_activation(s,\n",
    "                                    [res_act[0]],\n",
    "                                    state='reservoir',\n",
    "                                    units_to_plot = [i for i in range(20)], #plot the activation of the 20 first reseroir units (arbitrary choice)\n",
    "                                    plot_variation = False,\n",
    "                                    plot_sum = False)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the ESN\n",
    "nb_unique_words = len(word2one_hot_id)\n",
    "iss = 1\n",
    "nb_features = nb_unique_words\n",
    "set_seed(None) #we test on a different and random seed each time\n",
    "\n",
    "if continuous_sentence_training: # Alexis Juven's hyper-parameters optimized through random search\n",
    "    sr = 1.3\n",
    "    sparsity = 0.81\n",
    "    leak = 0.04\n",
    "    alpha_coef = 10.**(-3.7)\n",
    "else:\n",
    "    sr = 1.1\n",
    "    sparsity = 0.85\n",
    "    leak = 0.05\n",
    "    alpha_coef = 10.**(-3.5)\n",
    "\n",
    "\n",
    "\n",
    "# build an ESN online, i.e. trained with FORCE learning after each sample\n",
    "\n",
    "W = mat_gen.fast_spectral_initialization(N, spectral_radius=sr, proba = sparsity) #reservoir matrix\n",
    "Win = mat_gen.generate_input_weights(nbr_neuron=N, dim_input=nb_features, #input matrix\n",
    "                                    input_bias=True, input_scaling=iss)\n",
    "Wout = np.zeros((output_size, N+1)) #output matrix to be optimized\n",
    "\n",
    "\n",
    "reservoir = ESNOnline(lr = leak,\n",
    "                    W = W,\n",
    "                    Win = Win,\n",
    "                    Wout = Wout,\n",
    "                    alpha_coef = alpha_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advancement :\n",
      "0.0\n",
      "Advancement :\n",
      "0.1\n",
      "Advancement :\n",
      "0.2\n",
      "Advancement :\n",
      "0.3\n",
      "Advancement :\n",
      "0.4\n",
      "Advancement :\n",
      "0.5\n",
      "Advancement :\n",
      "0.6\n",
      "Advancement :\n",
      "0.7\n",
      "Advancement :\n",
      "0.8\n",
      "Advancement :\n",
      "0.9\n",
      "CPU Time to train :  151.40297259300132  s\n",
      "Saving the matrices ...\n",
      "ID for file saved : 0.3756041369113501\n",
      "Matrices saved !\n",
      "Testing on test set...\n",
      "End of testing\n",
      "Valid representations :  77 / 1000\n",
      "Exact representations :  58 / 1000\n",
      "Testing on train set...\n",
      "End of testing\n",
      "Valid representations :  562 / 1000\n",
      "Exact representations :  504 / 1000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if use_save:\n",
    "        Wout = np.load(pth+\"Wout\"+name_id+\".npy\", allow_pickle = True)\n",
    "        Win = np.load(pth+\"Win\"+name_id+\".npy\", allow_pickle = True)\n",
    "        W = np.load(pth+\"W\"+name_id+\".npy\", allow_pickle = True)\n",
    "        W = W.item()\n",
    "        reservoir = ESNOnline(lr = leak,\n",
    "                            W = W,\n",
    "                            Win = Win,\n",
    "                            Wout = Wout,\n",
    "                            alpha_coef = alpha_coef)\n",
    "\n",
    "    if not(use_save):\n",
    "        t1 = time.process_time()\n",
    "\n",
    "        for sent_nb in range(len(trainX)): #training sentences\n",
    "\n",
    "            if continuous_sentence_training:\n",
    "                wash_init_steps = 0 #we train at each step\n",
    "            else:\n",
    "                wash_init_steps = trainX[sent_nb].shape[0]-1 #we train only the last step\n",
    "\n",
    "\n",
    "            reservoir.reset_reservoir()\n",
    "            reservoir.train(inputs=np.array([trainX[sent_nb]]),\n",
    "                            teachers=np.array([[trainY[sent_nb]]*trainX[sent_nb].shape[0]]), #the teacher is always the same vector\n",
    "                            wash_nr_time_step=wash_init_steps,\n",
    "                            verbose=False)\n",
    "\n",
    "\n",
    "            if sent_nb%100 == 0 and verbose_training:\n",
    "                print(\"Advancement :\")\n",
    "                print( sent_nb/len(trainX))\n",
    "\n",
    "\n",
    "        t2 = time.process_time()\n",
    "        if verbose_training:\n",
    "            print(\"CPU Time to train : \", t2 - t1, \" s\")\n",
    "\n",
    "        ##saving\n",
    "        if not(minimal_mode):\n",
    "            print(\"Saving the matrices ...\")\n",
    "            rd_id = np.random.random()\n",
    "            print(\"ID for file saved : \"+ str(rd_id))\n",
    "            np.save(r\"saved_ESN/Wout\"+str(rd_id), Wout)\n",
    "            np.save(r\"saved_ESN/Win\"+str(rd_id), Win)\n",
    "            np.save(r\"saved_ESN/W\"+str(rd_id), W)\n",
    "            print(\"Matrices saved !\")\n",
    "\n",
    "        ##Testing\n",
    "        if verbose_training:\n",
    "            print(\"Testing on test set...\")\n",
    "        vtest, extest, rmsetest = test_on_test_set(reservoir, test_sentences, testX, testY, verbose_training, threshold_factor, True)\n",
    "\n",
    "        if minimal_mode:\n",
    "            print(str(nb_objects) + \",\" +str(vtest) + \",\" + str(extest) + \",\"+ str(rmsetest) + \",\" + str(t2-t1))\n",
    "\n",
    "        if not(minimal_mode):\n",
    "            print(\"Testing on train set...\") #to compare for overfitting estimation\n",
    "            vtr, extr, rmsetr = test_on_test_set(reservoir, train_sentences, trainX, trainY, True, threshold_factor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "With bias, Win matrix should be of shape (1000, 769) but is (1000, 57).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-292ab7001349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_with_sentences_ESN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreservoir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_concepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#plot final outputs on the first test sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-dd37ab63c6d0>\u001b[0m in \u001b[0;36mtest_with_sentences_ESN\u001b[0;34m(sentences, model, nb_concepts, threshold_factor)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_reservoir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_reservoir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/reservoirpy-0.2.0-py3.8.egg/reservoirpy/esn_online.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, verbose)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m## Autochecks of inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autocheck_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/reservoirpy-0.2.0-py3.8.egg/reservoirpy/esn_online.py\u001b[0m in \u001b[0;36m_autocheck_io\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"With bias, Win matrix should be of shape ({self.N}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{inputs_0.shape[0] + 1}) but is {self.Win.shape}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Win matrix should be of shape ({self.N}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: With bias, Win matrix should be of shape (1000, 769) but is (1000, 57)."
     ]
    }
   ],
   "source": [
    "if not(minimal_mode):\n",
    "        ##Qualitative testing\n",
    "\n",
    "        #sample sentences for model analysis\n",
    "        test_sent = [\"BEGIN on the middle is a green glass and that is a orange bowl END\", #0\n",
    "        \"BEGIN and on the middle is a green glass and that is a orange bowl END\",\n",
    "        \"BEGIN a blue bowl is on the right and on the right there is the blue bowl END\",\n",
    "        \"BEGIN on the middle there is the orange and the orange on the middle is orange END\", #3\n",
    "        \"BEGIN the orange is orange and on the middle there is the green cup END\",\n",
    "        \"BEGIN on the left there is a blue glass and this is a orange END\",\n",
    "        \"BEGIN the glass on the left is blue and the bowl on the right is green END\", #6\n",
    "        \"BEGIN the orange on the right is green and there is a blue cup on the middle END\",\n",
    "        \"BEGIN on the right there is a red glass and the cup on the middle is red END\",\n",
    "        \"BEGIN a green glass is on the right and on the left is a orange END\"] #9\n",
    "\n",
    "\n",
    "        outputs, vision = test_with_sentences_ESN(test_sent, reservoir, nb_concepts, threshold_factor)\n",
    "\n",
    "        #plot final outputs on the first test sentence\n",
    "        id = 0\n",
    "        plot_final_activation(outputs[id][-1], concepts_delimitations, output_id_to_concept_dict, nb_concepts, test_sent[id])\n",
    "\n",
    "\n",
    "        #plot and save to png the evolution of the outputs during the processing of the first test sentence (plots developped by Alexis Juven)\n",
    "\n",
    "\n",
    "        id = 0\n",
    "        s = test_sent[id]\n",
    "\n",
    "        if continuous_sentence_training:\n",
    "            output_fun = lambda x: x\n",
    "        else:\n",
    "            output_fun = sigmoid #sigmoid function is recommended when dealing with final learning\n",
    "\n",
    "        plot_concept_activation(s,\n",
    "                                outputs[id],\n",
    "                                concepts_delimitations,\n",
    "                                nb_concepts,\n",
    "                                savefig = True,\n",
    "                                sub_ttl_fig = s+ \" ESN\",\n",
    "                                output_function = output_fun)\n",
    "\n",
    "\n",
    "        ##reservoir activity visualisation\n",
    "        res_states, vis = test_with_sentences_ESN(test_sentences, reservoir, nb_concepts, 1)\n",
    "        s = test_sentences[500]\n",
    "\n",
    "        res_act , _ = get_int_states(reservoir, [s], one_chunck = False) #get reservoir states\n",
    "\n",
    "        plot_hidden_state_activation(s,\n",
    "                                    [res_act[0]],\n",
    "                                    state='reservoir',\n",
    "                                    units_to_plot = [i for i in range(20)], #plot the activation of the 20 first reseroir units (arbitrary choice)\n",
    "                                    plot_variation = False,\n",
    "                                    plot_sum = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concept_activation(sentence, activations, concepts_delim,nb_concepts, output_function = None, savefig=False, sub_ttl_fig='', ylims=(-0.4, 1.4)):\n",
    "    \"\"\"\n",
    "        Plots activation through time of the different concepts while hearing\n",
    "        the sentence. If output_function is not None, it is applied to the reservoir\n",
    "        output vector before plotting.\n",
    "        This is a reuse of a function developped by Alexis Juven.\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = activations.copy()\n",
    "    activation_threshold = 0.5\n",
    "\n",
    "    if output_function is not None:\n",
    "\n",
    "        activation_threshold = output_function(activation_threshold)\n",
    "\n",
    "        for i in range(outputs.shape[0]):\n",
    "            outputs[i, :] = output_function(outputs[i, :])\n",
    "\n",
    "\n",
    "    words = sentence.split(\" \")\n",
    "    max_nb_seen_objects = 2\n",
    "    nb_object_properties = 3\n",
    "\n",
    "    fig, axes = plt.subplots(nb_object_properties, max_nb_seen_objects, figsize=(25,20))\n",
    "\n",
    "\n",
    "    concept_delimitations = [t[0] for t in concepts_delim] + [concepts_delim[-1][1]]\n",
    "\n",
    "    for i in range(max_nb_seen_objects):\n",
    "\n",
    "        offset = i * nb_concepts\n",
    "\n",
    "        axes[0, i].set_title(\"Object \" + str(i+1), fontsize = 26)\n",
    "\n",
    "        for j in range(nb_object_properties):\n",
    "\n",
    "            ax = axes[j, i]\n",
    "            ax.plot(outputs[:, offset + concept_delimitations[j] : offset + concept_delimitations[j+1]], linewidth = 4)\n",
    "            ax.legend(param.CONCEPT_LISTS[j], loc = 2, fontsize = 26)\n",
    "\n",
    "            ax.set_yticks([0., 0.5, 1.])\n",
    "            ax.set_yticklabels([0., 0.5, 1.], fontsize = 24)\n",
    "\n",
    "            ax.set_ylim([ylims[0], ylims[1]])\n",
    "\n",
    "            ax.set_xticks(np.arange(len(words)))\n",
    "            ax.set_xticklabels(words, fontsize = 26)\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize = 28)\n",
    "\n",
    "            ax.plot(len(words) * [activation_threshold], '--', color = 'grey', linewidth = 3)\n",
    "\n",
    "    fig.suptitle(sentence, fontsize = 28)\n",
    "    plt.subplots_adjust(hspace = 0.3)\n",
    "\n",
    "    if savefig:\n",
    "        plt.savefig('sentence_'+sub_ttl_fig+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        fig.show()\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
